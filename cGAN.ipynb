{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy.random as R\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Dropout, MaxPooling2D, Embedding, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '.../Dataset_BUSI_with_GT'\n",
    "\n",
    "benign_folder = 'benign'\n",
    "malignant_folder = 'malignant'\n",
    "normal_folder = 'normal'\n",
    "\n",
    "benign_path = os.path.join(dataset_path, benign_folder)\n",
    "malignant_path = os.path.join(dataset_path, malignant_folder)\n",
    "normal_path = os.path.join(dataset_path, normal_folder)\n",
    "\n",
    "def move_non_mask_files(source_folder, output_folder):\n",
    "    # Create a new folder to store non-mask files\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of all file paths in the source folder\n",
    "    file_paths = glob.glob(os.path.join(source_folder, \"*\"))\n",
    "\n",
    "    # Move non-mask files to the new folder\n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        if \"_mask\" not in file_name:\n",
    "            destination_path = os.path.join(output_folder, file_name)\n",
    "            shutil.move(file_path, destination_path)\n",
    "\n",
    "    print(\"Non-mask files have been extracted to the 'non_mask_files' folder.\")\n",
    "\n",
    "move_non_mask_files(normal_path,output_folder='.../Dataset_BUSI_with_GT/normal_correct/')\n",
    "move_non_mask_files(benign_path,output_folder='.../Dataset_BUSI_with_GT/benign_correct/')\n",
    "move_non_mask_files(malignant_path,output_folder='.../Dataset_BUSI_with_GT/malignant_correct/')\n",
    "\n",
    "def select_random_images(folder_path, n):\n",
    "    image_filenames = os.listdir(folder_path)\n",
    "    random.shuffle(image_filenames)\n",
    "    selected_filenames = image_filenames[:n]\n",
    "    return selected_filenames\n",
    "\n",
    "normal_images = select_random_images('.../Dataset_BUSI_with_GT/normal_correct/', 10)\n",
    "benign_images = select_random_images('.../Dataset_BUSI_with_GT/benign_correct/', 10)\n",
    "malignant_images = select_random_images('.../Dataset_BUSI_with_GT/malignant_correct/', 10)\n",
    "\n",
    "data_augmentation = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    # elastic_deformation=True\n",
    ")\n",
    "\n",
    "for image_filename in benign_images + malignant_images:\n",
    "    if image_filename in benign_images:\n",
    "        class_name = 'benign'\n",
    "        class_path = '.../Dataset_BUSI_with_GT/benign_correct/'\n",
    "    else:\n",
    "        class_name = 'malignant'\n",
    "        class_path = '.../Dataset_BUSI_with_GT/malignant_correct/'\n",
    "\n",
    "    # load image\n",
    "    image_path = os.path.join(class_path, image_filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # data augmentation\n",
    "    augmented_images = data_augmentation.flow(np.expand_dims(image, axis=0), batch_size=1)\n",
    "    augmented_image = next(augmented_images)[0].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples():\n",
    "    pass\n",
    "\n",
    "def build_generator(latent_dim, n_classes=3):\n",
    "    in_label = Input(shape=(1,))\n",
    "\n",
    "    #Class-Label embedding\n",
    "    label = Embedding(n_classes, 50)(in_label)\n",
    "    n_nodes = 7 * 7\n",
    "\n",
    "    #Expanding class-label embedding\n",
    "    label = Dense(n_nodes)(label)\n",
    "\n",
    "    #Converting flat array as 2d image \n",
    "    label = Reshape((7,7, 1))(label)\n",
    "\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    n_nodes = 128 * 7 * 7\n",
    "\n",
    "    #expanding random noise vector and converting in 7x7x128 image\n",
    "    gen = Dense(n_nodes)(in_latent)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "\n",
    "    #Adding class-label 2d image to this random noise image\n",
    "    merge = Concatenate()([gen, label])\n",
    "\n",
    "    #Creating features in image by upsampling \n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "\n",
    "    #Converting final image to a 1 channel image\n",
    "    out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
    "    model = Model([in_latent, in_label], out_layer)\n",
    "    return model\n",
    "\n",
    "generator = build_generator(latent_dim)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_vector():\n",
    "    pass\n",
    "\n",
    "def generate_fake_samples():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(in_shape=(28,28,1), n_classes=3):\n",
    "    in_label = Input(shape=(1,))\n",
    "    label = Embedding(n_classes, 50)(in_label)\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    label = Dense(n_nodes)(label)\n",
    "    label = Reshape((in_shape[0], in_shape[1], 1))(label)\n",
    "    in_image = Input(shape=in_shape)\n",
    "    merge = Concatenate()([in_image, label])\n",
    "    disc = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    disc = LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = Conv2D(128, (3,3), strides=(2,2), padding='same')(disc)\n",
    "    disc = LeakyReLU(alpha=0.2)(disc)\n",
    "    disc = Flatten()(disc)\n",
    "    disc = Dropout(0.4)(disc)\n",
    "    out_layer = Dense(1, activation='sigmoid')(disc)\n",
    "    model = Model([in_image, in_label], out_layer)\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan():\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
